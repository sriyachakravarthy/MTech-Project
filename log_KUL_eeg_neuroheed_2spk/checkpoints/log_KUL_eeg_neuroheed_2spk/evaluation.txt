started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f39d51b91c0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=50, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=8, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Traceback (most recent call last):
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 121, in <module>
    main(args)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 64, in main
    solver.evaluate(test_generator)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 249, in evaluate
    self._load_model(f'{self.args.checkpoint_dir}/last_best_checkpoint.pt')
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 59, in _load_model
    checkpoint = torch.load(path, map_location='cpu')
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/serialization.py", line 1114, in load
    return _legacy_load(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/serialization.py", line 1338, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, 'v'.
E0306 10:44:07.354848 140012927009408 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1107043) of binary: /home/sriyar/miniconda3/envs/clear_voice_tse/bin/python
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-06_10:44:07
  host      : ailab-3080ti
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1107043)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f0548310370>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=50, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=8, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Traceback (most recent call last):
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 120, in <module>
    main(args)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 63, in main
    solver.evaluate(test_generator)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 229, in evaluate
    self._load_model(f'{self.args.checkpoint_dir}/last_best_checkpoint.pt')
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 58, in _load_model
    checkpoint = torch.load(path, map_location='cpu')
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/serialization.py", line 1114, in load
    return _legacy_load(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/serialization.py", line 1338, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, 'v'.
E0307 11:27:51.513208 139671939568256 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1306116) of binary: /home/sriyar/miniconda3/envs/clear_voice_tse/bin/python
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-07_11:27:51
  host      : ailab-3080ti
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1306116)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7fa469a79370>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=50, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=8, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Traceback (most recent call last):
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 120, in <module>
    main(args)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 63, in main
    solver.evaluate(test_generator)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 229, in evaluate
    self._load_model(f'{self.args.checkpoint_dir}/last_best_checkpoint.pt')
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 58, in _load_model
    checkpoint = torch.load(path, map_location='cpu')
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/serialization.py", line 1114, in load
    return _legacy_load(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/serialization.py", line 1338, in _legacy_load
    magic_number = pickle_module.load(f, **pickle_load_args)
_pickle.UnpicklingError: invalid load key, 'v'.
E0310 09:25:11.846168 140333307777664 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1494409) of binary: /home/sriyar/miniconda3/envs/clear_voice_tse/bin/python
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-10_09:25:11
  host      : ailab-3080ti
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1494409)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7fc660335370>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=50, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=8, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation

        Run model on reference(ref) and degraded(deg)
        Sample rate (fs) - No default. Must select either 8000 or 16000.
        Note there is narrow band (nb) mode only when sampling rate is 8000Hz.
       
Traceback (most recent call last):
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 120, in <module>
    main(args)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/train.py", line 63, in main
    solver.evaluate(test_generator)
  File "/home/sriyar/neuroheed/ClearerVoice-Studio/train/target_speaker_extraction/solver.py", line 249, in evaluate
    pesqi =  (pesq(self.args.audio_sr, a_tgt, a_tgt_est, 'wb') - pesq(self.args.audio_sr, a_tgt, a_mix, 'wb'))
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/pesq/_pesq.py", line 113, in pesq
    _check_fs_mode(mode, fs, USAGE)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/pesq/_pesq.py", line 39, in _check_fs_mode
    raise ValueError("no wide band mode if fs = 8000")
ValueError: no wide band mode if fs = 8000
E0310 09:35:08.734599 139905034785408 torch/distributed/elastic/multiprocessing/api.py:833] failed (exitcode: 1) local_rank: 0 (pid: 1495236) of binary: /home/sriyar/miniconda3/envs/clear_voice_tse/bin/python
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/typing_extensions.py", line 2853, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/clear_voice_tse/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 264, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
train.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2025-03-10_09:35:08
  host      : ailab-3080ti
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 1495236)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f29c21de370>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=50, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=8, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([13.4418], device='cuda:0')
Avg SNRi: 15.023564709147
Avg PESQi: 1.2537501866022747
Avg STOIi: 0.1466956227947133
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f1f67588eb0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=50, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=8, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([13.4417], device='cuda:0')
Avg SNRi: 15.023446308360702
Avg PESQi: 1.2533735103607178
Avg STOIi: 0.1466942730746292
[W505 15:29:50.030252656 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W505 15:29:50.030358779 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f54bcc67b80>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([12.6578], device='cuda:0')
Avg SNRi: 14.21282132150115
Avg PESQi: 1.1988622554540633
Avg STOIi: 0.13467221001528176
[rank0]:[W505 15:45:11.566960935 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. port: 8833, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. port: 8841, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
[W505 20:11:48.359220033 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W505 20:11:48.359320447 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f152190f7c0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([13.0354], device='cuda:0')
Avg SNRi: 14.767283812441116
Avg PESQi: 1.2125521604220073
Avg STOIi: 0.1416396638725575
[rank0]:[W505 20:25:41.189249405 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. port: 8820, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. port: 8823, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. port: 8825, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
[W505 20:27:32.182815289 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W505 20:27:32.182899469 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f6bc3d8f7c0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([12.6635], device='cuda:0')
Avg SNRi: 14.29577189637919
Avg PESQi: 1.181516745964686
Avg STOIi: 0.13293247659160423
[rank0]:[W505 20:42:31.699620468 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
W0506 05:34:15.790000 1872843 site-packages/torch/distributed/elastic/agent/server/api.py:719] Received Signals.SIGTERM death signal, shutting down workers
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 1872843 got signal: 15
[W506 08:50:52.610433780 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W506 08:50:52.610517582 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7fc7a4c93c10>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([12.8764], device='cuda:0')
Avg SNRi: 14.424371134417958
Avg PESQi: 1.221505795876185
Avg STOIi: 0.1363267769802396
[rank0]:[W506 09:04:24.041877407 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 864, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 683, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 500, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 67, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. port: 8839, useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
[W506 09:16:46.382373793 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W506 09:16:46.382418397 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f40c57437c0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([13.9928], device='cuda:0')
Avg SNRi: 15.030683191437504
Avg PESQi: 1.225737336874008
Avg STOIi: 0.14956837513226062
[rank0]:[W506 09:30:32.849307277 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W506 13:09:26.274474038 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W506 13:09:26.274575635 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7fbe532976d0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
[W506 13:15:24.581689331 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W506 13:15:24.581758356 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7fadfc66b6d0>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([13.9928], device='cuda:0')
Avg SNRi: 15.030683191437504
Avg PESQi: 1.225737336874008
Avg STOIi: 0.14956837513226062
[rank0]:[W506 13:23:22.596902872 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Avg SISNR:i tensor([12.8764], device='cuda:0')
Avg SNRi: 14.424371134417958
Avg PESQi: 1.221505795876185
Avg STOIi: 0.1363267769802396
[rank0]:[W506 13:29:10.947774882 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
--- Logging error ---
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2064703 got signal: 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/logging/__init__.py", line 1100, in emit
    msg = self.format(record)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/logging/__init__.py", line 943, in format
    return fmt.format(record)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/_logging/_internal.py", line 793, in format
    record.message = record.getMessage()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/logging/__init__.py", line 366, in getMessage
    msg = str(self.msg)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2064703 got signal: 15
Call stack:
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 719, in run
    logger.warning("Received %s death signal, shutting down workers", e.sigval)
Message: 'Received %s death signal, shutting down workers'
Arguments: (<Signals.SIGHUP: 1>,)
Traceback (most recent call last):
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 208, in <module>
    main()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/typing_extensions.py", line 3252, in wrapper
    return arg(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 204, in main
    launch(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launch.py", line 189, in launch
    run(args)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/run.py", line 909, in run
    elastic_launch(
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 138, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 260, in launch_agent
    result = agent.run()
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/metrics/api.py", line 137, in wrapper
    result = f(*args, **kwargs)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 711, in run
    result = self._invoke_run(role)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/agent/server/api.py", line 870, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/sriyar/miniconda3/envs/s4/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 84, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 2064703 got signal: 1
[W514 11:08:17.491300233 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W514 11:08:17.491455426 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f0eca16b970>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([12.8272], device='cuda:0')
Avg SNRi: 14.692138131439375
Avg PESQi: 1.212222658117612
Avg STOIi: 0.13965144786211023
[rank0]:[W514 11:22:19.261577860 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[W514 11:53:12.244808073 Utils.hpp:165] Warning: Environment variable NCCL_BLOCKING_WAIT is deprecated; use TORCH_NCCL_BLOCKING_WAIT instead (function operator())
[W514 11:53:12.244860170 Utils.hpp:136] Warning: Environment variable NCCL_ASYNC_ERROR_HANDLING is deprecated; use TORCH_NCCL_ASYNC_ERROR_HANDLING instead (function operator())
started on /home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk

namespace(seed=777, use_cuda=1, config=[<yamlargparse.Path object at 0x7f4ce49b3a00>], checkpoint_dir='/home/sriyar/neuroheed/log_KUL_eeg_neuroheed_2spk/checkpoints/log_KUL_eeg_neuroheed_2spk', train_from_last_checkpoint=1, evaluate_only=1, loss_type='sisdr', init_learning_rate=0.000125, lr_warmup=1, max_epoch=100, clip_grad_norm=5.0, batch_size=4, accu_grad=1, effec_batch_size=12, max_length=10, num_workers=8, causal=0, network_reference=namespace(cue='eeg'), network_audio=namespace(backbone='neuroheed', N=256, L=20, B=64, H=128, K=100, R=6), init_from='None', mix_lst_path='./data/KUL/mixture_data_list_2mix.csv', audio_direc='/data/sriyar/KUL_eeg/audio_8k/', reference_direc='/data/sriyar/KUL_eeg/eeg/', speaker_no=2, audio_sr=8000, ref_sr=128, local_rank=0, distributed=False, world_size=1, device=device(type='cuda'))
network_wrapper(
  (sep_network): neuroheed(
    (encoder): Encoder(
      (conv1d_U): Conv1d(1, 256, kernel_size=(20,), stride=(10,), bias=False)
    )
    (separator): rnn(
      (layer_norm): GroupNorm(1, 256, eps=1e-08, affine=True)
      (bottleneck_conv1x1): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
      (dual_rnn): ModuleList(
        (0-5): 6 x Dual_RNN_Block(
          (intra_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (inter_rnn): LSTM(64, 128, batch_first=True, bidirectional=True)
          (intra_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (inter_norm): GroupNorm(1, 64, eps=1e-08, affine=True)
          (intra_linear): Linear(in_features=256, out_features=64, bias=True)
          (inter_linear): Linear(in_features=256, out_features=64, bias=True)
        )
      )
      (prelu): PReLU(num_parameters=1)
      (mask_conv1x1): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
      (po_encoding): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (eeg_net): TransformerEncoder(
        (layers): ModuleList(
          (0-4): 5 x TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
            )
            (linear1): Linear(in_features=64, out_features=256, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=256, out_features=64, bias=True)
            (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (fusion): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
    )
    (decoder): Decoder(
      (basis_signals): Linear(in_features=256, out_features=20, bias=False)
    )
  )
)

Total number of parameters: 2884417 


Total number of trainable parameters: 2884417 

Start evaluation
Avg SISNR:i tensor([13.9928], device='cuda:0')
Avg SNRi: 15.030683191437504
Avg PESQi: 1.225737336874008
Avg STOIi: 0.14956837513226062
[rank0]:[W514 12:07:01.721016661 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
